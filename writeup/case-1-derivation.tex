\subsection*{1. symmetric case}

For this case, let $\beta_i = (1 - x) \gamma_0 + x \gamma_1$ and define $\beta_{ATE}$ likewise.

Recall we want to minimize
\begin{align*}
\min \E_x \left(\E_{\gamma_{0,1}}[(\beta_i - \beta_{i,post})^2]\right)
\end{align*}

One way we can rewrite these equations is as the effect of women vs men.
let the squared error (SE) be
\begin{align*}
	\sqrt{SE} &= \beta_i -  \beta_{i,post} = \underbrace{[(1-x) \gamma_0 + x \gamma_1]}_{\text{$\beta_i$}}  - \underbrace{[((\vec{x} - c \vec{\bar{x}})\E(\gamma) + c \beta_{ATE})]}_\text{$\beta_{i,post}$} \\
	  &= [(1-x) \gamma_0 + x \gamma_1]  - [((1-x) - c (1 - \bar{x})) \E(\gamma_0) + (x - c \bar{x})\E(\gamma_1) + c((1-\bar{x}) \gamma_0 + \bar{x} \gamma_1)] \\
	  % &= [(1-x) \gamma_0 + x \gamma_1  - (x - c \bar{x})\E(\gamma) + c((1-\bar{x}) \gamma_0 + \bar{x} \gamma_1)] \\
\end{align*}

Because this is a function of $x$, We can then describe

$\beta_{i}^{men} = \beta_i (x=1)$ and similarly for other terms to get

So 
\begin{align*}
	\beta_i^{men} &= \gamma_1 \\
	\beta_i^{post,men} &= -c_{men} ( 1- \bar{x}) \bar{\gamma_0} + (1 - c_{men}\bar{x}) \bar{\gamma_1} + c_{men} [ (1-\bar{x}) \gamma_0 + \bar{x}\gamma_1] \\
	\beta_i^{women} &= \gamma_0 \\
	\beta_i^{post,women} &= [ 1 - c_{wom}(1-\bar{x}) ]\E(\gamma_0) - c_{wom} \bar{x} \E(\gamma_1) + c_{wom} (1- \bar{x}) \gamma_0 + c_{wom} \bar{x} \gamma_1 \\
\end{align*} 

this can be broken down into

\begin{align*}
	\sqrt{ SE } &= (\beta_i^{men} - \beta_i^{post, men} )+ (\beta_i^{wom} - \beta_i^{post, wom}) \\
\end{align*} 

let 
 \begin{align*}
	 W^{men} &=  (\beta_i^{men} - \beta_i^{post, men}) \\
			&= (1 - \bar{x} c_{men}) (\gamma_1 - \bar{\gamma_1}) - c_{men} ( 1 - \bar{x}) (\gamma_0 - \bar{\gamma_0}) \\
			&= (c_{wom} (1 - \bar{x})) (\gamma_1 - \bar{\gamma_1}) - c_{men} ( 1 - \bar{x}) (\gamma_0 - \bar{\gamma_0}) \\
	 W^{wom} &=  (\beta_i^{wom} - \beta_i^{post, wom}) \\
			 &= [ 1 - c_{wom}(1 - \bar{x}) ] (\gamma_0 - \bar{\gamma_0}) - c_{wom} \bar{x} (\gamma_1 - \bar{\gamma_1}) \\
			 &= [ c_{men} \bar{x}] (\gamma_0 - \bar{\gamma_0}) - c_{wom} \bar{x} (\gamma_1 - \bar{\gamma_1}) \\
\end{align*} 
and recall that
\begin{align*}
	c_{i} &= \frac{(1-x)(1-\bar{x})\Var(\gamma_0) + x\bar{x}\Var(\gamma_1)}{(1-\bar{x})^2\Var(\gamma_0) + \bar{x}^2\Var(\gamma_1)} \\
		  % &= \frac{(1-x)(1-\bar{x}) + x\bar{x}}{(1-\bar{x})^2 + \bar{x}^2} 
\end{align*}

so if you are a man, then 

\begin{align*}
	c_{men} =  \frac{\bar{x}\Var(\gamma_1)}{(1-\bar{x})^2\Var(\gamma_0) + \bar{x}^2\Var(\gamma_1)}
\end{align*}

and likewise if you are a woman, then

\begin{align*}
	c_{woman} = \frac{(1-\bar{x})\Var(\gamma_0)}{(1-\bar{x})^2\Var(\gamma_0) + \bar{x}^2\Var(\gamma_1)}
\end{align*}


% and 
% \begin{align*}
% 	W_{men}^2 &= \left(\frac{(1-\bar{x})^4}{((1-\bar{x})^2 + \bar{x}^2)^2}\right) \Var(\gamma_1) +  \frac{\bar{x}^2 (1-\bar{x})^2}{((1-\bar{x})^2 + \bar{x}^2)^2} \Var(\gamma_0) \\
% 			  &= \big(\frac{(1-\bar{x})^2 \Var(\gamma_1)} {(1-\bar{x})^2 + \bar{x}^2} \\
% 	W_{women}^2 &= \left(\frac{(\bar{x})^4}{((1-\bar{x})^2 + \bar{x}^2)^2}\right) \Var(\gamma_0) + \frac{\bar{x}^2 (1-\bar{x})^2}{((1-\bar{x})^2 + \bar{x}^2)^2} \Var(\gamma_1) \\
% 				&= \frac{(\bar{x})^2 \Var(\gamma_0) }{(1-\bar{x})^2 + \bar{x}^2} \\
% \end{align*} 


% so then taking the mean ($E_{x}$) with respect to $x$, we can write the mean squared error (MSE) as
% \begin{align*}
% 	MSE &= p W_{men}^2 + (1 - p)W_{wom}^2 \\
% 	&= p \left(\frac{(1-\bar{x})^4\Var(\gamma_1) + ( \bar{x}^2 (1-\bar{x})^2 ) \Var(\gamma_0)}{((1-\bar{x})^2 + \bar{x}^2)^2}\right) + (1-p)\left(\frac{(\bar{x})^4 \Var(\gamma_0) + ( \bar{x}^2 (1-\bar{x})^2 ) \Var(\gamma_1) }{((1-\bar{x})^2 + \bar{x}^2)^2}\right) \\
% \end{align*} 

% so using the fact that $\Var(\gamma_0) = \Var(\gamma_1) = 1$ we get

% \begin{align*}
% 	 MSE &= p \left(\frac{(1-\bar{x})^4 + ( \bar{x}^2 (1-\bar{x})^2 ) }{((1-\bar{x})^2 + \bar{x}^2)^2}\right) + (1-p)\left(\frac{(\bar{x})^4  + ( \bar{x}^2 (1-\bar{x})^2 ) }{((1-\bar{x})^2 + \bar{x}^2)^2}\right) \\
% 	 MSE &= p \left(\frac{(1-\bar{x})^2 }{(1-\bar{x})^2 + \bar{x}^2}\right) + (1-p)\left(\frac{(\bar{x})^2 }{(1-\bar{x})^2 + \bar{x}^2}\right) \\
% 			 &= p \frac{(1-\bar{x})^2}{(1-\bar{x})^2 + \bar{x}^2} + (1-p) \frac{\bar{x}^2}{(1-\bar{x})^2 + \bar{x}^2}
% \end{align*} 

% In other words for individual $i$ we have that

% \begin{align*}
% 	 MSE &= p (1 - c_{men} \bar{x}) + (1-p) (1 - c_{women} (1 - \bar{x})) \\
% 	 MSE &= p \left(1 - \frac{\bar{x}^2}{(1-\bar{x})^2 + \bar{x}^2}\right) + (1-p) \left(1 - \frac{(1-\bar{x})^2}{(1-\bar{x})^2 + \bar{x}^2} \right) \\
% 	 MSE &= p \left(\frac{(1 - \bar{x})^2}{(1-\bar{x})^2 + \bar{x}^2}\right) + (1-p) \left(\frac{\bar{x}^2}{(1-\bar{x})^2 + \bar{x}^2} \right) \\
% 	 MSE &= p \left[ (1 - \bar{x})c_{wom} \right] + (1-p) \left[ \bar{x}c_{men} \right] \\
% \end{align*} 

% Interestingly this implies a FOC of

% \begin{align*}
% 	\frac{\partial MSE }{\partial \bar{x}} &= p \left(\frac{2 \bar{x} (1 - \bar{x})}{((1-\bar{x})^2 + \bar{x}^2)^2}\right) - (1-p) \left(\frac{2 \bar{x} (1 - \bar{x})}{((1-\bar{x})^2 + \bar{x}^2)^2} \right) = 0 \\
% 	\frac{\partial MSE}{\partial \bar{x}} &= (2p -1) \left(\frac{2 \bar{x} (1 - \bar{x})}{((1-\bar{x})^2 + \bar{x}^2)^2}\right) = 0
% \end{align*} 

% meaning we've retrieved our original FOC.



And, allowing for arbitrary variances, we can say that

\begin{align*}
	W_{men}^2 &= \left(\frac{(1 - \bar{x})^4}{((1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1))^2}\right)\Var(\gamma_0)^2 \Var(\gamma_1)  \\
			  & -  \frac{2 (1 - \bar{x})^2[\bar{x} (1-\bar{x})]}{((1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1))^2} \Var(\gamma_1) \Var(\gamma_0) \Cov(\gamma_0, \gamma_1)  \\
			  & + \frac{\bar{x}^2 (1-\bar{x})^2}{((1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1))^2} \Var(\gamma_1)^2 \Var(\gamma_0) \\
			  &= \Var(\gamma_0) \Var(\gamma_1) \bigg(\frac{(1 - \bar{x})^4}{((1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1))^2}\Var(\gamma_0)  \\
			  & -  \frac{2 (1 - \bar{x})^2[\bar{x} (1-\bar{x})]}{((1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1))^2} \Cov(\gamma_0, \gamma_1)  \\
			  & + \frac{\bar{x}^2 (1-\bar{x})^2}{((1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1))^2} \Var(\gamma_1) \bigg) \\
\end{align*} 


\begin{align*}
	W_{women}^2 &= \left(\frac{(\bar{x})^4}{((1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1))^2}\right)\Var(\gamma_1)^2 \Var(\gamma_0)  \\
				& -  \frac{2 \bar{x}^2[\bar{x} (1-\bar{x})]}{((1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1))^2} \Var(\gamma_1) \Var(\gamma_0) \Cov(\gamma_0, \gamma_1)  \\
				& + \frac{\bar{x}^2 (1-\bar{x})^2}{((1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1))^2} \Var(\gamma_0)^2 \Var(\gamma_1) \\
				&= \Var(\gamma_0) \Var(\gamma_1) \bigg(\frac{(\bar{x})^4}{((1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1))^2}\Var(\gamma_1) \\
				& -  \frac{2 \bar{x}^2[\bar{x} (1-\bar{x})]}{((1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1))^2} \Cov(\gamma_0, \gamma_1)  \\
				& + \frac{\bar{x}^2 (1-\bar{x})^2}{((1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1))^2} \Var(\gamma_0) \bigg) \\
\end{align*} 


So letting $\Cov(\gamma_0, \gamma_1) = 0$ we get

\begin{align*}
	W_{men}^2 &= \Var(\gamma_0) \Var(\gamma_1) \bigg(\frac{(1 - \bar{x})^2 }{(1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1)} \bigg) \\
\end{align*} 

\begin{align*}
	W_{women}^2 &= \Var(\gamma_0) \Var(\gamma_1) \bigg(\frac{(\bar{x})^2 }{(1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1)} \bigg) \\
\end{align*} 



Now observe that if $\alpha = \Var(\gamma_1)$ and $\beta = \Var(\gamma_0)$ then
\begin{align*}
	\alpha W_{women}^2 + \beta W_{men}^2 &= \Var(\gamma_0) \Var(\gamma_1) \big[ \frac{\Var(\gamma_1) \bar{x}^2 + \Var(\gamma_0) (1- \bar{x})^2}{(1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1)} \big] \\
										 &= \Var(\gamma_0) \Var(\gamma_1)
\end{align*} 
So we can write
\begin{align*}
	\alpha W^{2}_{women} &= \Var(\gamma_0) \Var(\gamma_1) - \beta W^{2}_{men} \\
	W^{2}_{women} &= \frac{\Var(\gamma_0) \Var(\gamma_1) - \beta W^{2}_{men}}{\alpha} \\
	W^{2}_{women} &= \frac{\Var(\gamma_0) \Var(\gamma_1) - \Var(\gamma_0) W^{2}_{men}}{\Var(\gamma_1)} \\
\end{align*} 

And thus conclude

\begin{align*}
	MSE &= (1 - p) W^2_{women} + p W^2_{men} \\
	MSE &= p W^{2}_{men} + (1-p) \bigg(\frac{\Var(\gamma_0) \Var(\gamma_1) - \Var(\gamma_0) W^{2}_{men}}{\Var(\gamma_1)} \bigg) \\
	MSE &= p W^{2}_{men} + (1-p) \bigg(\frac{\Var(\gamma_0) \Var(\gamma_1) - \Var(\gamma_0) W^{2}_{men}}{\Var(\gamma_1)} \bigg) \\
	&= \frac{\bigg(p[\Var(\gamma_0) + \Var(\gamma_1)]- \Var(\gamma_0)\bigg) W^{2}_{men} + (1-p) \Var(\gamma_0) \Var(\gamma_1)}{\Var(\gamma_1)}
\end{align*} 

Thus when $p > \frac{\Var(\gamma_0)}{\Var(\gamma_0) + \Var(\gamma_1)}$ we can clearly see that MSE is minimized when $W_{men}^2$ is minimized (when $\bar{x} = 1$). And inversely when $p < \frac{\Var(\gamma_0)}{\Var(\gamma_0) + \Var(\gamma_1)}$ MSE is minimized when $W_{men}^2$ is maximaximized (when $\bar{x} = 0$).
In other words, when the proportion of men is  $p > \frac{\Var(\gamma_0)}{\Var(\gamma_0) + \Var(\gamma_1)}$ it is optimal to have only men ($\bar{x}$) in the trial, and vice versa. And when there are eqal number of men and women in the population,  $MSE$ does not depend on $W_{men}^2$ and thus has equal error of $\frac{\Var(\gamma_0)}{\Var(\gamma_0) + \Var(\gamma_1)}$ for any $\bar{x}$.

We can also solve this using the first order conditions.

\begin{align*}
	MSE = (1-p)W_{women}^2 + p W_{men}^2 &= \Var(\gamma_0) \Var(\gamma_1) \big[ \frac{(1-p)\bar{x}^2 + p(1- \bar{x})^2}{(1-\bar{x})^2 \Var(\gamma_0) + \bar{x}^2 \Var(\gamma_1)} \big]
\end{align*} 

Which gives a derivative of
\begin{align*}
	\frac{MSE}{d\bar{x}} = -\frac{ 2 \Var(\gamma_0) \Var(\gamma_1) (1 - \bar{x}) \bar{x} \big[\Var(\gamma_0) (p - 1) + \Var(\gamma_1) p\big] }{(\Var(\gamma_0) (\bar{x} - 1)^2 + \Var(\gamma_1) \bar{x}^2)^2}
\end{align*} 

Here we can see that we still have roots $\bar{x} = 0$ and $\bar{x} = 1$ and all that changes is we get a variances-weighted edge-case whenever $(\Var(\gamma_0) + \Var(\gamma_1))p - \Var(\gamma_0) = 0$

And to get which is the minizing solution we can observe the SOC 
\begin{align*}
	\frac{MSE}{d \bar{x}^2} &= -\frac{2 \Var(\gamma_0) \Var(\gamma_1) [ \Var(\gamma_0) (p - 1) + \Var(\gamma_1) p ] [ \Var(\gamma_0) (2 x + 1) (x - 1)^2 + \Var(\gamma_1) x^2 (2 x - 3) ]}{[ \Var(\gamma_0) (x - 1)^2 + \Var(\gamma_1) x^2 ]^3}
\end{align*} 

From the second order condition, we can look at the two roots. We can see that the numerator reduces to two cases. When $p > \frac{\Var(\gamma_0)}{(\Var(\gamma_0) + \Var(\gamma_1))}$, then we can observe that the numerator is positive for the root $\bar{x} = 1$. Conversely, the numerator is positive when  $\bar{x} = 0$
We can also see this outlined in the simulations below.
% insert png figure named Figure_1.png here
\begin{figure}[ht!]
  \centering
	\includegraphics[width=0.8\textwidth]{simulate-sym}
  % \caption{Plot of $\frac{\partial J}{\partial \bar{x}}$}
	\caption{First column contains the simulated error for different population proportions with the population proportion shown by the blue vertical line and point of minimum error shown with the red vertical line. The second column has the analytic error computed in the math above as well as a vertical line showing the first critical point. The third column shows the first derivative with respect to $\bar{x}$.} 
	\label{fig:simulate-sym}
\end{figure}

